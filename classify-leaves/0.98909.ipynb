{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import math\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import timm\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm import tqdm\n",
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split, cross_validate, StratifiedKFold, cross_val_score\n",
    "\n",
    "# Metric\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "\n",
    "# Augmentation\n",
    "import albumentations\n",
    "from albumentations.pytorch.transforms import ToTensorV2\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(f'Using device: {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "固定随机种子，保证结果可复现。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "seed = 415\n",
    "os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one-hot 编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "path = '/kaggle/input/classify-leaves'\n",
    "labels_file_path = os.path.join(path, 'train.csv')\n",
    "sample_submission_path = os.path.join(path, 'test.csv')\n",
    "\n",
    "df = pd.read_csv(labels_file_path)\n",
    "sub_df = pd.read_csv(sample_submission_path)\n",
    "labels_unique = df['label'].unique()\n",
    "\n",
    "\n",
    "le = LabelEncoder()\n",
    "le.fit(df['label'])\n",
    "df['label'] = le.transform(df['label'])\n",
    "label_map = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "label_inv_map = {v: k for k, v in label_map.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数据增强"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "def get_train_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(320, 320),\n",
    "            albumentations.HorizontalFlip(p=0.5),\n",
    "            albumentations.VerticalFlip(p=0.5),\n",
    "            albumentations.Rotate(limit=180, p=0.7),\n",
    "            albumentations.RandomBrightnessContrast(),\n",
    "            albumentations.ShiftScaleRotate(\n",
    "                shift_limit=0.25, scale_limit=0.1, rotate_limit=0\n",
    "            ),\n",
    "            albumentations.Normalize(\n",
    "                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0, always_apply=True\n",
    "            ),\n",
    "            ToTensorV2(p=1.0),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def get_valid_transforms():\n",
    "    return albumentations.Compose(\n",
    "        [\n",
    "            albumentations.Resize(320, 320),\n",
    "            albumentations.Normalize(\n",
    "                [0.485, 0.456, 0.406], [0.229, 0.224, 0.225],\n",
    "                max_pixel_value=255.0, always_apply=True\n",
    "            ),\n",
    "            ToTensorV2(p=1.0)\n",
    "        ]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class LeafDataset(Dataset):\n",
    "    def __init__(self, images_filepaths, labels, transform=None):\n",
    "        self.images_filepaths = images_filepaths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images_filepaths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_filepath = self.images_filepaths[idx]\n",
    "        image = cv2.imread(image_filepath)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image=image)[\"image\"]\n",
    "        return image, label\n",
    "\n",
    "def accuracy(output, target):\n",
    "    y_pred = torch.softmax(output, dim=1)\n",
    "    y_pred = torch.argmax(y_pred, dim=1).cpu()\n",
    "    target = target.cpu()\n",
    "\n",
    "    return accuracy_score(target, y_pred)\n",
    "\n",
    "\n",
    "def calculate_f1_macro(output, target):\n",
    "    y_pred = torch.softmax(output, dim=1)\n",
    "    y_pred = torch.argmax(y_pred, dim=1).cpu()\n",
    "    target = target.cpu()\n",
    "\n",
    "    return f1_score(target, y_pred, average='macro')\n",
    "\n",
    "\n",
    "class MetricMonitor:\n",
    "    def __init__(self, float_precision=3):\n",
    "        self.float_precision = float_precision\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.metrics = defaultdict(lambda: {\"val\": 0, \"count\": 0, \"avg\": 0})\n",
    "\n",
    "    def update(self, metric_name, val):\n",
    "        metric = self.metrics[metric_name]\n",
    "\n",
    "        metric[\"val\"] += val\n",
    "        metric[\"count\"] += 1\n",
    "        metric[\"avg\"] = metric[\"val\"] / metric[\"count\"]\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" | \".join(\n",
    "            [\n",
    "                \"{metric_name}: {avg:.{float_precision}f}\".format(\n",
    "                    metric_name=metric_name, avg=metric[\"avg\"],\n",
    "                    float_precision=self.float_precision\n",
    "                )\n",
    "                for (metric_name, metric) in self.metrics.items()\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "def adjust_learning_rate(optimizer, epoch, params, batch=0, nBatch=None):\n",
    "    \"\"\" adjust learning of a given optimizer and return the new learning rate \"\"\"\n",
    "    new_lr = calc_learning_rate(epoch, params['lr'], params['epochs'], batch, nBatch)\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group['lr'] = new_lr\n",
    "    return new_lr\n",
    "\n",
    "\n",
    "\"\"\" learning rate schedule \"\"\"\n",
    "def calc_learning_rate(epoch, init_lr, n_epochs, batch=0, nBatch=None, lr_schedule_type='cosine'):\n",
    "    if lr_schedule_type == 'cosine':\n",
    "        t_total = n_epochs * nBatch\n",
    "        t_cur = epoch * nBatch + batch\n",
    "        lr = 0.5 * init_lr * (1 + math.cos(math.pi * t_cur / t_total))\n",
    "    elif lr_schedule_type is None:\n",
    "        lr = init_lr\n",
    "    else:\n",
    "        raise ValueError('do not support: %s' % lr_schedule_type)\n",
    "    return lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'model': 'seresnext50_32x4d',\n",
    "    # 'model': 'resnet50d',\n",
    "    'device': device,\n",
    "    'lr': 1e-3,\n",
    "    'batch_size': 64,\n",
    "    'num_workers': 0,\n",
    "    'epochs': 50,\n",
    "    'out_features': df['label'].nunique(),\n",
    "    'weight_decay': 1e-5\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "metadata": {}
   },
   "outputs": [],
   "source": [
    "class LeafNet(nn.Module):\n",
    "    def __init__(self, model_name=params['model'], out_features=params['out_features'],\n",
    "                 pretrained=True):\n",
    "        super().__init__()\n",
    "        self.model = timm.create_model(model_name, pretrained=pretrained)\n",
    "        n_features = self.model.fc.in_features\n",
    "        self.model.fc = nn.Linear(n_features, out_features)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.model(x)\n",
    "        return x\n",
    "\n",
    "def train(train_loader, model, criterion, optimizer, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.train()\n",
    "    nBatch = len(train_loader)\n",
    "    stream = tqdm(train_loader)\n",
    "    for i, (images, target) in enumerate(stream, start=1):\n",
    "        images = images.to(params['device'], non_blocking=True)\n",
    "        target = target.to(params['device'], non_blocking=True)\n",
    "        output = model(images)\n",
    "        loss = criterion(output, target)\n",
    "        f1_macro = calculate_f1_macro(output, target)\n",
    "        acc = accuracy(output, target)\n",
    "        metric_monitor.update('Loss', loss.item())\n",
    "        metric_monitor.update('F1', f1_macro)\n",
    "        metric_monitor.update('Accuracy', acc)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr = adjust_learning_rate(optimizer, epoch, params, i, nBatch)\n",
    "        stream.set_description(\n",
    "            \"Epoch: {epoch}. Train.      {metric_monitor}\".format(\n",
    "                epoch=epoch,\n",
    "                metric_monitor=metric_monitor)\n",
    "        )\n",
    "    return metric_monitor.metrics['Accuracy'][\"avg\"]\n",
    "\n",
    "def validate(val_loader, model, criterion, epoch, params):\n",
    "    metric_monitor = MetricMonitor()\n",
    "    model.eval()\n",
    "    stream = tqdm(val_loader)\n",
    "    with torch.no_grad():\n",
    "        for i, (images, target) in enumerate(stream, start=1):\n",
    "            images = images.to(params['device'], non_blocking=True)\n",
    "            target = target.to(params['device'], non_blocking=True)\n",
    "            output = model(images)\n",
    "            loss = criterion(output, target)\n",
    "            f1_macro = calculate_f1_macro(output, target)\n",
    "            acc = accuracy(output, target)\n",
    "            metric_monitor.update('Loss', loss.item())\n",
    "            metric_monitor.update('F1', f1_macro)\n",
    "            metric_monitor.update('Accuracy', acc)\n",
    "            stream.set_description(\n",
    "                \"Epoch: {epoch}. Validation. {metric_monitor}\".format(\n",
    "                    epoch=epoch,\n",
    "                    metric_monitor=metric_monitor)\n",
    "            )\n",
    "    return metric_monitor.metrics['Accuracy'][\"avg\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "metadata": {}
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch: 1. Train.      Loss: 2.531 | F1: 0.262 | Accuracy: 0.377: 100%|██████████| 144/144 [02:50<00:00,  1.18s/it]\n",
      "Epoch: 1. Validation. Loss: 1.415 | F1: 0.425 | Accuracy: 0.575: 100%|██████████| 144/144 [00:43<00:00,  3.28it/s]\n",
      "Epoch: 2. Train.      Loss: 0.966 | F1: 0.557 | Accuracy: 0.699:  84%|████████▍ | 121/144 [01:47<00:21,  1.09it/s]"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''\n",
    "os.environ['HTTP_PROXY'] = \"http://127.0.0.1:7890\"\n",
    "os.environ['HTTPS_PROXY'] = \"http://127.0.0.1:7890\"\n",
    "\n",
    "kf = StratifiedKFold(n_splits=2)\n",
    "\n",
    "for k, (train_index, test_index) in enumerate(kf.split(df['image'], df['label'])):\n",
    "    train_img, valid_img = df['image'][train_index], df['image'][test_index]\n",
    "    train_labels, valid_labels = df['label'][train_index], df['label'][test_index]\n",
    "\n",
    "    train_paths = '/kaggle/input/classify-leaves/' + train_img\n",
    "    valid_paths = '/kaggle/input/classify-leaves/' + valid_img\n",
    "    test_paths = '/kaggle/input/classify-leaves/' + sub_df['image']\n",
    "\n",
    "    train_dataset = LeafDataset(images_filepaths=train_paths.values,\n",
    "                                labels=train_labels.values,\n",
    "                                transform=get_train_transforms())\n",
    "    valid_dataset = LeafDataset(images_filepaths=valid_paths.values,\n",
    "                                labels=valid_labels.values,\n",
    "                                transform=get_valid_transforms())\n",
    "    train_loader = DataLoader(\n",
    "        train_dataset, batch_size=params['batch_size'], shuffle=True,\n",
    "        num_workers=params['num_workers'], pin_memory=True,\n",
    "    )\n",
    "\n",
    "    val_loader = DataLoader(\n",
    "        valid_dataset, batch_size=params['batch_size'], shuffle=False,\n",
    "        num_workers=params['num_workers'], pin_memory=True,\n",
    "    )\n",
    "    model = LeafNet()\n",
    "    model = nn.DataParallel(model)\n",
    "    model = model.to(params['device'])\n",
    "    criterion = nn.CrossEntropyLoss().to(params['device'])\n",
    "    optimizer = torch.optim.AdamW(model.parameters(), lr=params['lr'], weight_decay=params['weight_decay'])\n",
    "\n",
    "    for epoch in range(1, params['epochs'] + 1):\n",
    "        train(train_loader, model, criterion, optimizer, epoch, params)\n",
    "        acc = validate(val_loader, model, criterion, epoch, params)\n",
    "        torch.save(model.state_dict(), f\"./checkpoints/{params['model']}_{k}flod_{epoch}epochs_accuracy{acc:.5f}_weights.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_img, valid_img = df['image'], df['image']\n",
    "train_labels, valid_labels = df['label'], df['label']\n",
    "\n",
    "train_paths = '../input/classify-leaves/' + train_img\n",
    "valid_paths = '../input/classify-leaves/' + valid_img\n",
    "test_paths = '../input/classify-leaves/' + sub_df['image']\n",
    "\n",
    "model_name = ['seresnext50_32x4d', 'resnet50d']\n",
    "model_path_list = [\n",
    "    '../input/checkpoints/seresnext50_32x4d_0flod_50epochs_accuracy0.97985_weights.pth',\n",
    "    '../input/checkpoints/seresnext50_32x4d_1flod_50epochs_accuracy0.97872_weights.pth',\n",
    "    '../input/checkpoints/seresnext50_32x4d_2flod_36epochs_accuracy0.97710_weights.pth',\n",
    "    '../input/checkpoints/seresnext50_32x4d_3flod_40epochs_accuracy0.98303_weights.pth',\n",
    "    '../input/checkpoints/seresnext50_32x4d_4flod_46epochs_accuracy0.97899_weights.pth',\n",
    "    '../input/checkpoints/resnet50d_0flod_40epochs_accuracy0.98087_weights.pth',\n",
    "    '../input/checkpoints/resnet50d_1flod_46epochs_accuracy0.97710_weights.pth',\n",
    "    '../input/checkpoints/resnet50d_2flod_32epochs_accuracy0.97656_weights.pth',\n",
    "    '../input/checkpoints/resnet50d_3flod_38epochs_accuracy0.97953_weights.pth',\n",
    "    '../input/checkpoints/resnet50d_4flod_50epochs_accuracy0.97791_weights.pth',\n",
    "]\n",
    "\n",
    "model_list = []\n",
    "for i in range(len(model_path_list)):\n",
    "    if i < 5:\n",
    "        model_list.append(LeafNet(model_name[0]))\n",
    "    if 5 <= i < 10:\n",
    "        model_list.append(LeafNet(model_name[1]))\n",
    "    model_list[i] = nn.DataParallel(model_list[i])\n",
    "    model_list[i] = model_list[i].to(params['device'])\n",
    "    init = torch.load(model_path_list[i])\n",
    "    model_list[i].load_state_dict(init)\n",
    "    model_list[i].eval()\n",
    "    model_list[i].cuda()\n",
    "\n",
    "    \n",
    "labels = np.zeros(len(test_paths)) # Fake Labels\n",
    "test_dataset = LeafDataset(images_filepaths=test_paths,\n",
    "                            labels=labels,\n",
    "                            transform=get_valid_transforms())\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, batch_size=128, shuffle=False,\n",
    "    num_workers=10, pin_memory=True\n",
    ")\n",
    "\n",
    "\n",
    "predicted_labels = []\n",
    "pred_string = []\n",
    "preds = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for (images, target) in test_loader:\n",
    "        images = images.cuda()\n",
    "        onehots = sum([model(images) for model in model_list]) / len(model_list)\n",
    "        for oh, name in zip(onehots, target):\n",
    "            lbs = label_inv_map[torch.argmax(oh).item()]\n",
    "            preds.append(dict(image=name, labels=lbs))\n",
    "\n",
    "df_preds = pd.DataFrame(preds)\n",
    "sub_df['label'] = df_preds['labels']\n",
    "sub_df.to_csv('submission.csv', index=False)\n",
    "sub_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
